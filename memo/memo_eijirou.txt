・全体的な方針について
    ・時間が許す限り、色々なモデルを作って強いものを採用したい。


・モンテカルロ木探索について
    ・evaluationの値としてNNを使うといいかも。
        ・AlphaGoZeroと一緒かな？
    ・指手の確率をNNで出力するのは難しい。
        ・1手先の局面の評価値をNNで全て取得すれば確率に変換できるが、実行速度が気になる。
        ・出力をfrom_x, from_y, to_x, to_yのようにすれば直接的に作れなくもない。
            ・出力ノード数は750個ぐらい。
            ・反則手も学習させることになる。
            ・ほとんど無駄なノードなので学習が大変そう。


・モンテカルロ木探索以外でやってもよさそうなこと
    ・探索について
        ・評価関数を用いて、上位n個以外の指手を枝刈りする。
            ・n=4ぐらいだと思っているが、評価関数の質にもよる。
            ・可能な指手がn個未満のこともある。
        ・Mini-Max法を実装する。
            ・毎回盤面を反転させているので。事実上Nega-Max法になりそう。
        ・αカット、βカットを実装する。
            ・暫定評価値で枝刈りすることもできる。
        ・反復深化法または move ordering を用いて探索を高速化させる。
            ・余裕があれば。
        ・ネガスカウト法や null window search を用いて探索を高速化させる。
            ・余裕があれば。
        ・千日手をふまえて評価値を操作する。
        ・うまく時間管理を行う。
    ・評価関数について
        ・ランダム遷移シミュレーションで大量の棋譜を生成する。
            ・重複を削除したいのでハッシュテーブルがほしい。
        ・詰みについて教師あり学習を行う。
        ・初期盤面を変えながら、自己対戦による学習を行う。


・機械学習（主にニューラルネットワーク）について
    ・NN自体はできそう。
        ・自作NNを用いてMNISTの(4,9)の2分類を行なったところ、検証データで約96%の精度を出せた。
        ・(0,1)の2分類なら99%以上の精度が出る。
    ・どう学習させるかが難しい。
    ・ランダムな遷移を繰り返すものを作ることで、ある程度バリエーションがある棋譜を大量に生成できる。
        ・駒を打つ確率は少し下げたほうがよさそう。
        ・動かす駒を先に決める？
    ・詰みと詰みの直前に関しては教師あり学習を行うことができる。
    ・1手先にNNを適用することで、自己対戦による学習をある程度高速に行うことができる。
        ・初期盤面を変えることで、局面にバリエーションをもたせることができる。
    ・左右反転によってデータ拡張をすることができる。
    ・今のところ、NNの適用は10秒間に10^4回程度と見積もっている。


・NNの暫定的なモデル
    ・NNUE評価関数を参考にした。
    ・535 -Affine-> 32 -ReLU-> 32 -Affine-> 32 -ReLU-> 32 -Affine-> 1 -Sigmoid-> 1
    ・optimizer: Adam(lr=0.001, beta1=0.9, beta2=0.999, epsilon=1e-7)
    ・誤差逆伝播法において、勾配消失に対処するため、Sigmoid関数の微分を1とした。
    ・盤面の各マスを21次元のone-hot-encodingで表し、持ち駒を10次元で表すと、入力次元数が535になる。
    ・学習がうまくいかなかった場合、入力形式やNNのモデルを変えるとよさそう。
        ・マスにある駒ではなく、マスに利きがある駒を1にする入力形式も考えられる。
            ・入力の0と1のバランスがよくなって、汎用性が高くなったり、学習が高速化されるかもしれない。
        ・NNUEではHalfKPという特徴量を入力として与えている。
